{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,text\n",
    "import psycopg2\n",
    "import os\n",
    "import io\n",
    "import time \n",
    "from psycopg2 import sql\n",
    "import timeit\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_postgres_engine(user, password, host, port, db_name):\n",
    "    \"\"\"Create a SQLAlchemy engine for PostgreSQL.\"\"\"\n",
    "    connection_string = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db_name}\"\n",
    "    engine = create_engine(connection_string)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_postgres_engine(config.DB_USER,config.DB_PASSWORD,config.DB_HOST,config.DB_PORT,config.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_file(filename):\n",
    "    # Open and read the file\n",
    "    with open(filename, 'r') as file:\n",
    "        sql_script = file.read()\n",
    "    \n",
    "    # Begin a connection\n",
    "    with engine.connect() as connection:\n",
    "        # Start a transaction\n",
    "        with connection.begin():\n",
    "            # Split script into individual statements\n",
    "            statements = sql_script.split(';')\n",
    "            \n",
    "            # Execute each statement\n",
    "            for statement in statements:\n",
    "                # Remove whitespace\n",
    "                clean_statement = statement.strip()\n",
    "                \n",
    "                # Skip empty statements\n",
    "                if clean_statement:\n",
    "                    try:\n",
    "                        # Execute each statement\n",
    "                        connection.execute(text(clean_statement))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error executing statement: {clean_statement}\")\n",
    "                        print(f\"Error details: {e}\")\n",
    "                        raise\n",
    "        \n",
    "        print(f\"SQL file {filename} executed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table_into_db(file_path, table_name, conn_params):\n",
    "\n",
    "    metrics = {\n",
    "        'file_name': file_path.split(\"/\")[-1],\n",
    "        'insertion_time_ms': 0,\n",
    "        'wall_time_ms': 0,\n",
    "        'rows_inserted': 0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Establish connection\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "        conn.set_session(autocommit=False)\n",
    "        \n",
    "        try:\n",
    "            wall_start_time = time.time()\n",
    "\n",
    "            with conn.cursor() as cur:\n",
    "                # Start timing\n",
    "               \n",
    "                # Open the CSV file and copy\n",
    "                with open(file_path, 'r') as f:\n",
    "                    insertion_start = timeit.default_timer()\n",
    "                    cur.copy_expert(\n",
    "                        sql.SQL('COPY {} FROM STDIN WITH (FORMAT CSV, HEADER TRUE)').format(\n",
    "                            sql.Identifier(table_name)\n",
    "                        ), \n",
    "                        f\n",
    "                    )\n",
    "                    insertion_end = timeit.default_timer()\n",
    "                    metrics['insertion_time_ms'] = (insertion_end - insertion_start) * 1000\n",
    "                   \n",
    "                # Commit the transaction\n",
    "                conn.commit()\n",
    "                \n",
    "                # Calculate wall time\n",
    "                wall_end_time = time.time()\n",
    "                metrics['wall_time_ms'] = (wall_end_time - wall_start_time) * 1000\n",
    "\n",
    "                cur.execute(sql.SQL('SELECT COUNT(*) FROM {}').format(sql.Identifier(table_name)))\n",
    "                metrics['rows_inserted'] = cur.fetchone()[0]\n",
    "                        \n",
    "                    \n",
    "                # Print metrics\n",
    "                print(f\"Import Metrics for {file_path}:\")\n",
    "                print(f\"Insertion Time: {metrics['insertion_time_ms']:.2f} ms\")\n",
    "                print(f\"Wall Time: {metrics['wall_time_ms']:.2f} ms\")\n",
    "                print(f\"Rows Inserted: {metrics['rows_inserted']}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        except Exception as inner_e:\n",
    "            # Rollback if any error occurs\n",
    "            conn.rollback()\n",
    "            print(f\"Error importing {file_path}: {inner_e}\")\n",
    "        \n",
    "        finally:\n",
    "            # Ensure connection is closed\n",
    "            conn.close()\n",
    "            return metrics \n",
    "    \n",
    "    except psycopg2.Error as conn_e:\n",
    "        print(f\"Database connection error: {conn_e}\")\n",
    "        return metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_params = {\n",
    "    'dbname': config.DB_NAME,\n",
    "    'user': config.DB_USER,\n",
    "    'password': config.DB_PASSWORD,\n",
    "    'host': config.DB_HOST,\n",
    "    'port': config.DB_PORT\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = {\n",
    "    'ACC':'accelerometer_data',\n",
    "    'BVP':'blood_volume_pulse',\n",
    "    'Dexcom':'interstitial_glucose',\n",
    "    'EDA':'electrodermal_activity',\n",
    "    'HR':'heart_rate_data',\n",
    "    'IBI':'ibi_data',\n",
    "    'TEMP':'temperature_data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mention scale factor\n",
    "scale_factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_to_places_string(number):\n",
    "    \n",
    "    # Ensure the input is a valid integer within range\n",
    "    if not isinstance(number, int) or not (0 <= number <= 999):\n",
    "        raise ValueError(\"Input must be an integer between 0 and 999.\")\n",
    "\n",
    "    # Extract hundreds, tens, and ones\n",
    "    hundreds = number // 100\n",
    "    tens = (number // 10) % 10\n",
    "    ones = number % 10\n",
    "\n",
    "    # Format into the desired string\n",
    "    result = f\"{hundreds}{tens}{ones}\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_use = [integer_to_places_string(i) for i in range(1,scale_factor+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_files = ['ACC','BVP','Dexcom','EDA','HR','IBI','TEMP']  ## if want to ignore a table remove it from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL file sql_scripts/create_schema.sql executed successfully!\n",
      "Import Metrics for ../new_data/Demographics.csv:\n",
      "Insertion Time: 3.24 ms\n",
      "Wall Time: 3.84 ms\n",
      "Rows Inserted: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'Demographics.csv',\n",
       " 'insertion_time_ms': 3.2363749924115837,\n",
       " 'wall_time_ms': 3.8442611694335938,\n",
       " 'rows_inserted': 16}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Schema\n",
    "run_sql_file(os.path.join(config.SQL_SCRIPTS_PATH,'create_schema.sql'))\n",
    "\n",
    "## Load Demographics Data not to be included in data insertion timings - one time load\n",
    "demographic_path = os.path.join(config.TRANSFORM_DATA_PATH,'Demographics.csv') \n",
    "load_table_into_db(demographic_path,'demographics',conn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Metrics for ../new_data/001/ACC_001.csv:\n",
      "Insertion Time: 97880.30 ms\n",
      "Wall Time: 97887.20 ms\n",
      "Rows Inserted: 20296428\n",
      "Import Metrics for ../new_data/001/BVP_001.csv:\n",
      "Insertion Time: 192493.17 ms\n",
      "Wall Time: 192499.13 ms\n",
      "Rows Inserted: 40592838\n",
      "Import Metrics for ../new_data/001/Dexcom_001.csv:\n",
      "Insertion Time: 54.38 ms\n",
      "Wall Time: 56.81 ms\n",
      "Rows Inserted: 2561\n",
      "Import Metrics for ../new_data/001/EDA_001.csv:\n",
      "Insertion Time: 12286.29 ms\n",
      "Wall Time: 12288.02 ms\n",
      "Rows Inserted: 2537046\n",
      "Import Metrics for ../new_data/001/HR_001.csv:\n",
      "Insertion Time: 2456.72 ms\n",
      "Wall Time: 2458.53 ms\n",
      "Rows Inserted: 634188\n",
      "Import Metrics for ../new_data/001/IBI_001.csv:\n",
      "Insertion Time: 1082.72 ms\n",
      "Wall Time: 1083.74 ms\n",
      "Rows Inserted: 266366\n",
      "Import Metrics for ../new_data/001/TEMP_001.csv:\n",
      "Insertion Time: 11940.48 ms\n",
      "Wall Time: 11943.48 ms\n",
      "Rows Inserted: 2537040\n",
      "Import Metrics for ../new_data/002/ACC_002.csv:\n",
      "Insertion Time: 100324.15 ms\n",
      "Wall Time: 100329.31 ms\n",
      "Rows Inserted: 40448658\n",
      "Import Metrics for ../new_data/002/BVP_002.csv:\n",
      "Insertion Time: 194929.63 ms\n",
      "Wall Time: 194938.42 ms\n",
      "Rows Inserted: 80897311\n",
      "Import Metrics for ../new_data/002/Dexcom_002.csv:\n",
      "Insertion Time: 73.52 ms\n",
      "Wall Time: 76.00 ms\n",
      "Rows Inserted: 4680\n",
      "Import Metrics for ../new_data/002/EDA_002.csv:\n",
      "Insertion Time: 11205.68 ms\n",
      "Wall Time: 11207.82 ms\n",
      "Rows Inserted: 5056068\n",
      "Import Metrics for ../new_data/002/HR_002.csv:\n",
      "Insertion Time: 2674.75 ms\n",
      "Wall Time: 2676.07 ms\n",
      "Rows Inserted: 1263860\n",
      "Import Metrics for ../new_data/002/IBI_002.csv:\n",
      "Insertion Time: 2026.03 ms\n",
      "Wall Time: 2027.59 ms\n",
      "Rows Inserted: 740374\n",
      "Import Metrics for ../new_data/002/TEMP_002.csv:\n",
      "Insertion Time: 11436.46 ms\n",
      "Wall Time: 11439.36 ms\n",
      "Rows Inserted: 5056032\n"
     ]
    }
   ],
   "source": [
    "list_of_metrics = []\n",
    "for i in range(0,scale_factor):\n",
    "    folder_path = os.path.join(config.TRANSFORM_DATA_PATH,folder_to_use[i])\n",
    "    \n",
    "    for file in accepted_files:\n",
    "         \n",
    "        file_path = os.path.join(folder_path,f'{file}_{folder_to_use[i]}.csv')\n",
    "        metrics = load_table_into_db(file_path,table_names[file],conn_params)\n",
    "\n",
    "        list_of_metrics.append(metrics)\n",
    "\n",
    "\n",
    "report_df = pd.DataFrame(list_of_metrics)\n",
    "total_df =pd.DataFrame(report_df.select_dtypes(include=['float','int']).sum()).T \n",
    "total_df.insert(0,'file_name',['Total'])\n",
    "report_df = pd.concat([report_df,total_df],axis=0).reset_index(drop=True)\n",
    "report_df.to_csv(os.path.join(config.RESULTS_PATH,f\"insertion_stats_scale_{scale_factor}.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>insertion_time_ms</th>\n",
       "      <th>wall_time_ms</th>\n",
       "      <th>rows_inserted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC_001.csv</td>\n",
       "      <td>97880.302583</td>\n",
       "      <td>97887.200594</td>\n",
       "      <td>20296428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BVP_001.csv</td>\n",
       "      <td>192493.171584</td>\n",
       "      <td>192499.131203</td>\n",
       "      <td>40592838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dexcom_001.csv</td>\n",
       "      <td>54.378125</td>\n",
       "      <td>56.807041</td>\n",
       "      <td>2561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDA_001.csv</td>\n",
       "      <td>12286.285875</td>\n",
       "      <td>12288.019180</td>\n",
       "      <td>2537046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HR_001.csv</td>\n",
       "      <td>2456.716084</td>\n",
       "      <td>2458.532810</td>\n",
       "      <td>634188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IBI_001.csv</td>\n",
       "      <td>1082.720250</td>\n",
       "      <td>1083.739996</td>\n",
       "      <td>266366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TEMP_001.csv</td>\n",
       "      <td>11940.480792</td>\n",
       "      <td>11943.480015</td>\n",
       "      <td>2537040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACC_002.csv</td>\n",
       "      <td>100324.153000</td>\n",
       "      <td>100329.308987</td>\n",
       "      <td>40448658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BVP_002.csv</td>\n",
       "      <td>194929.632708</td>\n",
       "      <td>194938.419819</td>\n",
       "      <td>80897311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dexcom_002.csv</td>\n",
       "      <td>73.518292</td>\n",
       "      <td>76.000214</td>\n",
       "      <td>4680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EDA_002.csv</td>\n",
       "      <td>11205.675500</td>\n",
       "      <td>11207.819939</td>\n",
       "      <td>5056068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HR_002.csv</td>\n",
       "      <td>2674.745125</td>\n",
       "      <td>2676.066875</td>\n",
       "      <td>1263860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IBI_002.csv</td>\n",
       "      <td>2026.030334</td>\n",
       "      <td>2027.591228</td>\n",
       "      <td>740374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEMP_002.csv</td>\n",
       "      <td>11436.461125</td>\n",
       "      <td>11439.360142</td>\n",
       "      <td>5056032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Total</td>\n",
       "      <td>640864.271377</td>\n",
       "      <td>640911.478043</td>\n",
       "      <td>200333450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name  insertion_time_ms   wall_time_ms  rows_inserted\n",
       "0      ACC_001.csv       97880.302583   97887.200594     20296428.0\n",
       "1      BVP_001.csv      192493.171584  192499.131203     40592838.0\n",
       "2   Dexcom_001.csv          54.378125      56.807041         2561.0\n",
       "3      EDA_001.csv       12286.285875   12288.019180      2537046.0\n",
       "4       HR_001.csv        2456.716084    2458.532810       634188.0\n",
       "5      IBI_001.csv        1082.720250    1083.739996       266366.0\n",
       "6     TEMP_001.csv       11940.480792   11943.480015      2537040.0\n",
       "7      ACC_002.csv      100324.153000  100329.308987     40448658.0\n",
       "8      BVP_002.csv      194929.632708  194938.419819     80897311.0\n",
       "9   Dexcom_002.csv          73.518292      76.000214         4680.0\n",
       "10     EDA_002.csv       11205.675500   11207.819939      5056068.0\n",
       "11      HR_002.csv        2674.745125    2676.066875      1263860.0\n",
       "12     IBI_002.csv        2026.030334    2027.591228       740374.0\n",
       "13    TEMP_002.csv       11436.461125   11439.360142      5056032.0\n",
       "14           Total      640864.271377  640911.478043    200333450.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compress the data \n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypertable_sizes(conn_params):\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        hypertable_schema AS schema,\n",
    "        hypertable_name AS table_name,\n",
    "        pg_size_pretty(hypertable_size(hypertable_schema || '.' || hypertable_name)) AS total_size,\n",
    "        hypertable_size(hypertable_schema || '.' || hypertable_name) AS total_size_bytes\n",
    "    FROM \n",
    "        timescaledb_information.hypertables\n",
    "    ORDER BY \n",
    "        total_size_bytes DESC;\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = psycopg2.connect(**conn_params)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/51/y2_6x05j1hjgtnzwshx1dgt80000gn/T/ipykernel_28905/2278943484.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "size_df = get_hypertable_sizes(conn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size MB  total_size_bytes    11665.640625\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Size MB \",size_df.select_dtypes(include=['float','int']).sum()/(1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema</th>\n",
       "      <th>table_name</th>\n",
       "      <th>total_size</th>\n",
       "      <th>total_size_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public</td>\n",
       "      <td>blood_volume_pulse</td>\n",
       "      <td>6877 MB</td>\n",
       "      <td>7211220992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>public</td>\n",
       "      <td>accelerometer_data</td>\n",
       "      <td>3753 MB</td>\n",
       "      <td>3934855168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public</td>\n",
       "      <td>electrodermal_activity</td>\n",
       "      <td>437 MB</td>\n",
       "      <td>458326016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public</td>\n",
       "      <td>temperature_data</td>\n",
       "      <td>436 MB</td>\n",
       "      <td>456728576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public</td>\n",
       "      <td>heart_rate_data</td>\n",
       "      <td>96 MB</td>\n",
       "      <td>101007360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>public</td>\n",
       "      <td>ibi_data</td>\n",
       "      <td>66 MB</td>\n",
       "      <td>68878336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>public</td>\n",
       "      <td>interstitial_glucose</td>\n",
       "      <td>1264 kB</td>\n",
       "      <td>1294336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   schema              table_name total_size  total_size_bytes\n",
       "0  public      blood_volume_pulse    6877 MB        7211220992\n",
       "1  public      accelerometer_data    3753 MB        3934855168\n",
       "2  public  electrodermal_activity     437 MB         458326016\n",
       "3  public        temperature_data     436 MB         456728576\n",
       "4  public         heart_rate_data      96 MB         101007360\n",
       "5  public                ibi_data      66 MB          68878336\n",
       "6  public    interstitial_glucose    1264 kB           1294336"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_query(sql_file_path, params):\n",
    "    # Read the SQL template\n",
    "    with open(sql_file_path, 'r') as file:\n",
    "        template_content = file.read()\n",
    "    \n",
    "    # Render the template with parameters\n",
    "    template = Template(template_content)\n",
    "    query = template.render(params)\n",
    "    \n",
    "    return query\n",
    "\n",
    "def execute_sql_file(conn_params, sql_file_path, params=None):\n",
    "   \n",
    "    try:\n",
    "        query = render_query(sql_file_path,params)        \n",
    "        # Establish database connection\n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "\n",
    "        with conn.cursor() as cur:\n",
    "                # Start timing\n",
    "                execution_start = timeit.default_timer()\n",
    "                cur.execute(sql.SQL(query))\n",
    "                execution_end = timeit.default_timer()\n",
    "        # Close the connection\n",
    "\n",
    "        execution_time_taken = (execution_end-execution_start)*1000\n",
    "\n",
    "        print(\"Time of Execution:\",execution_time_taken)\n",
    "        conn.close()\n",
    "        \n",
    "        return execution_time_taken\n",
    "    \n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(f\"Error executing SQL file: {error}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "         conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of Execution: 4712.430790998042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4712.430790998042"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_sql_file(conn_params,os.path.join(config.SQL_SCRIPTS_PATH,\"query_0.sql\"),{'list_of_participants':(1,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
